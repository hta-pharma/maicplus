---
title: 'Matching-Adjusted Indirect Comparison: data simulation'
output:
  html_document:
    df_print: paged
bibliography: references.bib
---

```{r, echo= FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE,
                      tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

In this vignette, we simulate the datasets that we will be using to run unanchored and anchored matching-adjusted indirect comparison. We use the method described in Bender et al. to simulate survival times. [@Bender2005] We assume that we have five covariates of which two are continuous and three are binary.

We use notation from National Institute for Health and Care Excellence (NICE) Decision Support Unit (DSU) Technical Support Document (TSD) 18 to denote treatment effects for different population. [@phillippo2016a] We denote treatment effect of $B$ vs $A$ in target population $P$ when $X = 0$ as $d_{AB(P)}(0)$. Let us generate the first study with only treatments $A$ and $B$, denote this study population as $P=AB$ and call this the $AB$ study.

For the $AB$ study, we generate a dataset with a treatment indicator, two continuous variables ($x_1$ and $x_2$) and three binary variables ($x_3$, $x_4$, and $x_5$). We further assume that $x_2$ and $x_3$ are prognostic variables and $x_1$, $x_4$, and $x_5$ are effect modifiers. We assume that prognostic variables are not effect modifying, but the effect modifiers are also prognostic. We simulate baseline hazard from a Weibull distribution and censoring times from an exponential distribution.

For easier identification, we give these covariates corresponding variable names as following:

* $x_1$ - age
* $x_2$ - 
* Treatment - a character variable with the name of the intervention treatment 

Furthermore, let us assume that these variables are standardized a priori.


```{r}
library(MASS) #for mvrnorm

# Code is adapted from https://stats.stackexchange.com/questions/135124/how-to-create-a-toy-survival-time-to-event-data-with-right-censoring

# N: sample size    
# lambda: scale parameter in baseline hazard function
# rho: shape parameter in baseline hazard function
# rateC: rate parameter of the exponential distribution of C
# beta: vector of coefficients for prognostic factors
# gamma: vector of coefficients for effect modifiers
# d0: coefficient for the treatment effect when X = 0
# xcutoff: vector of points where the continuous variables are cut to make them to binary predictors. 
# The bigger the number less frequent the covariates are equal to 1.

simulWeib <- function(N, lambda, rho, rateC, beta, gamma, d0, xcutoff, seed = 1)
{
  set.seed(seed) #seed number that is used to make simulation replicable
  
  xcutoff <- runif(3, min = -0.5, max = 0.5) #make cutoff for binary random
  
  # generate 5 covariates with some correlation
  Sigma <- outer(1:5, 1:5, function(x,y) 0.2^abs(x-y)) #variance covariance
  x <- mvrnorm(n = N, rep(0, 5), Sigma)
  for(i in 3:5){
    x[,i] <- ifelse(x[,i] > xcutoff[i-2], 1, 0) # make it a binary predictor
  }
  colnames(x) <- paste0("x", 1:5)
  
  # Define age
  x[,1] <- runif(1, min = 20, max = 30) + x[,1] * runif(1, min = )
  
  treat <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))

  # linear predictor
  lp <- x %*% beta + x %*% gamma * treat + d0 * treat
  
  # Weibull latent event times
  v <- runif(n=N)
  Tlat <- (-log(v) / (lambda * exp(lp)))^(1 / rho)

  # censoring times
  C <- rexp(n=N, rate=rateC)

  # follow-up times and event indicators
  Time <- pmin(Tlat, C)
  Event <- as.numeric(Tlat <= C)

  # data set
  data.frame(USUBJID=1:N, Time=Time, Event=Event, 
             x1=x[,1], x2 = x[,2], x3 = x[,3], treat = treat)
}
```


# References