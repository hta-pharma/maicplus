---
title: 'Matching-Adjusted Indirect Comparison: unanchored example using the maicplus package'
output:
  html_document:
    df_print: paged
bibliography: references.bib
---

```{r, echo= FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE,
                      tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

# Introduction

This document describes the steps required to perform a matching-adjusted indirect comparison (MAIC) analysis using the <tt>maicplus</tt> package in R for a disconnected treatment network where the endpoint of interest is either time-to-event (e.g. overall survival) or binary (e.g. objective tumor
response).

The methods described in this document are based on those originally described by Signorovitch et al. 2010 and described in the National Institute for Health and Care Excellence (NICE) Decision Support Unit (DSU) Technical Support Document (TSD) 18. [@signorovitch2010; @phillippo2016a]

MAIC methods are often required when: 

* There is no common comparator treatment to link a clinical trial of a new intervention to clinical trials of other treatments in a given disease area. For example if the only study of a new intervention is a single arm trial with no control group. This is commonly referred to as an unanchored MAIC.
* A common comparator is available to link a clinical trial of a new intervention to a clinical trial of one other treatment in a given disease area but there are substantial differences in patient demographic or disease characteristics that are believed to be treatment effect modifiers. This is commonly referred to as an anchored MAIC.

The premise of MAIC methods is to adjust for between-trial differences in patient demographic or disease characteristics at baseline. When a common treatment comparator or ‘linked network’ are unavailable, a MAIC assumes that differences between absolute outcomes that would be observed in each trial are entirely explained by imbalances in prognostic variables and treatment effect
modifiers. Prognostic variables are those that are predictive of disease outcomes, independent of the treatment received. For example, older patients may have increased risk of death compared to younger patients. Treatment effect modifiers are those variables that influence the relative effect of one treatment compared to another. For example patients with a better performance status may experience a larger treatment benefit than those with a worse performance status. Under this assumption, every prognostic variable and every treatment effect modifier that is imbalanced between the two studies must be available. This assumption is generally considered very difficult to
meet. [@phillippo2016a] There are several ways of identifying prognostic variables/treatment effect modifiers to be used in the MAIC analyses, some of which include:

* Clinical expertise (when available to a project)
* Published papers/previous submissions (what has been identified in the disease area previously)
* Univariable/multivariable regression analyses to identify which covariates
have a significant effect on the outcome
* Subgroup analyses of clinical trials may identify interactions between patient characteristics and the relative treatment effect

## Example Scenario

For the purposes of this example, we present an unanchored MAIC of two treatments in lung cancer with the treatments being compared labelled 'intervention' and 'comparator'. The two endpoints being compared are overall survival (a time to event outcome) and objective response (a binary outcome). The data used in this example have been simulated to resemble that of clinical trial data. The data available are:

* Individual patient data from a single arm study of 'intervention'
* Aggregate summary data for 'comparator'. This could be from a single arm study of the comparator or from one arm of a randomized controlled trial.
* Psuedo patient data from the comparator study. This is not required for the
matching process but is needed to derive the relative treatment effects between
the intervention and comparator.

In this example scenario, age, sex, the Eastern Cooperative Oncology Group performance status (ECOG PS), smoking status, and number of previous treatments have been identified as imbalanced prognostic variables/treatment effect modifiers.

# Set up packages and data

## Install packages

The following packages are required to run this example:

```{r}
library(dplyr)
library(survival) # for survfit
library(survminer) # for ggsurvplot
library(boot) # for boot

setwd("~/GitHub/maicplus/inst/dev/combined")
source("functions_all.R")

setwd("~/GitHub/maicplus")
devtools::load_all()
```

## Read in the data

To perform unanchored MAICs, the following data is required:

* Individual patient data (IPD) from the intervention trial
* Baseline data from the comparator trial
* Pseudo data of outcomes for the comparator trial

Simulated data for the above is provided with the <tt>maicplus</tt> package.

### Intervention trial IPD

This example reads in and combines data from three standard simulated data sets (adsl, adrs and adtte) which are saved as '.csv' files. The data may need some manipulation to standardize the variable names to ensure they are the same in all datasets.

The variables needed for the time to event analyses are:

* Time - a numeric variable
* Event - a binary variable (event=1, censor=0)
* Treatment - a character variable with the name of the intervention treatment 

The variables needed for the binary event analyses are:

* Response - a binary variable (event=1, no event=0)
* Treatment - a character variable with the name of the intervention treatment

For the matching variables:

* All binary variables to be used in the matching should be coded 1 and 0 (see
example for sex below).
* The variable names need to be listed in a character vector called
<tt>match_cov</tt>.

```{r}
# Read in relevant ADaM data

# added a new variable: number of previous therapies in the new adsl.csv
# adsl$n_pr_ther <- sample(1:4, size = dim(adsl)[1], replace = TRUE)
setwd("~/GitHub/maicplus/inst/dev/combined")
adsl <- read.csv("adsl.csv")

adrs <- read.csv(system.file("extdata", "adrs.csv", package = "maicplus",
                             mustWork = TRUE))
adtte <- read.csv(system.file("extdata", "adtte.csv", package = "maicplus",
                              mustWork = TRUE))

adsl <- adsl %>% # Data containing the matching variables
  mutate(SEX=ifelse(SEX=="Male", 1, 0)) # Coded 1 for males and 0 for females

adrs <- adrs %>% # Response data
  filter(PARAM=="Response") %>%
  transmute(USUBJID, ARM, response=AVAL)

adtte <- adtte %>% # Time to event data (overall survival)
  filter(PARAMCD=="OS") %>%
  mutate(Event=1-CNSR) %>% #Set up coding as Event = 1, Censor = 0
  transmute(USUBJID, ARM, Time=AVAL, Event)

# Combine all intervention data
intervention_input <- adsl %>%
  full_join(adrs, by=c("USUBJID", "ARM")) %>%
  full_join(adtte, by=c("USUBJID", "ARM"))

# Change to lower case
names(intervention_input) <- tolower(names(intervention_input))
intervention_input <- intervention_input %>% rename(Time = time, Event = event)

# Create a variable for age squared
intervention_input <- intervention_input %>%
  mutate(age_squared = age^2)
head(intervention_input)

match_cov <- c("age", "age_squared", "sex", "smoke", "ecog0", "n_pr_ther")
```

### Baseline data from the comparator trial

The aggregate baseline characteristics from the comparator trial are needed as a data frame. Number of patients (N) should be provided if possible. Other possible characteristics include mean, median, or standard deviation of continuous variables and proportion for binary variables. Only a single summary measure of mean or median can be provided for continuous variables and if standard deviation is provided, mean of the continuous variable also needs to be specified. Possible missingness of binary varibles should be accounted for by subtracting the denominator by the missing count i.e. proportion = count / (N - missing).

The naming of comparator trial needs to be consistent with the IPD data variable name. The naming should be followed by the following suffixes accordingly: "_prop", "_mean", "_median", "_sd". The R code below demonstrates some examples. 

```{r}
# Baseline aggregate data for the comparator population
# Getting data from csv
# target_pop <- read.csv(system.file("extdata", "aggregate_data_updated.csv",
#                                   package = "MAIC", mustWork = TRUE))
# TODO: Template?

# Define target_pop manually
target_pop <- data.frame(
  N = 300,
  age_mean = 50.06,
  age_sd = 3.23,
  sex_prop = 147/300, #male proportion
  smoke_prop = 58/(300-2), #2 missing patients
  ecog0_prop = 105/300,
  n_pr_ther_median = 3 #number of previous therapies
)
```

As described by Phillippo et al., balancing on both mean and standard deviation for continuous variables (where possible) may be considered in some cases. [@phillippo2016a] If a standard deviation is provided in the comparator population, preprocessing is done so that in the target population, $E(X^2)$ is calculated using the variance formula $Var(X)=E(X^{2})-E(X)^{2}$. As we will discuss in later sections, $E(X^2)$ in the comparator population is then used to center the $X^2$ variable in the IPD data.

If a median is provided, IPD is preprocessed to categorize the variable into binary. All the values in the IPD that are higher than the comparator population median is assigned a value of 1. Conversely, all values that are lower are assigned a value of 0. Comparator population median is replaced by 0.5 to adjust to the categorization in the IPD data.

The following function <tt>preprocess_data</tt> is used to preprocess different types of data, including standard deviation and median, into a format that is suitable for calculating weights for MAIC.

```{r}
preprocessed <- preprocess_data(intervention_input, target_pop)
intervention_data <- preprocessed$intervention_data
target_pop <- preprocessed$target_pop
```

# Estimate weights

## Statistical theory 

As described in the supplementary appendix of Signorovitch et al. 2010, we must find a $\beta$, such that re-weighting baseline characteristics for the intervention, $x_{i,ipd}$ exactly matches the mean baseline characteristics for the comparator data source for which only aggregate data is available.[@signorovitch2010]

The weights are given by:
$$\hat{\omega}_i=\exp{(x_{i,ipd}.\beta)}\qquad (1)$$ 

That is, we must find a solution to: 
$$\bar{x}_{agg}\sum_{i=1}^n \exp{(x_{i,ipd}.\beta)}  = \sum_{i=1}^n
x_{i,ipd}.\exp{(x_{i,ipd}.\beta)}\qquad (2)$$ 

This estimator is equivalent to solving the equation 
$$ 0 = \sum_{i=1}^n (x_{i,ipd} -  \bar{x}_{agg}).\exp{(x_{i,ipd}.\beta)}\qquad (3)$$ 

without loss of generality, it can be assumed that $\bar{x}_{agg} = 0$ (e.g we could transform baseline characteristics in both trials by subtracting  $\bar{x}_{agg}$) leaving the estimator $$0 = \sum_{i=1}^n(x_{i,ipd})\exp{(x_{i,ipd}.\beta)}\qquad (4)$$ 

The right hand side of this estimator is the first derivative of $$ Q(\beta) = \sum_{i=1}^n  \exp{(x_{i,ipd}.\beta)}\qquad (5) $$ As described by Signorovitch et al (supplemental appendix), $Q(\beta)$ is convex and therefore any finite solution to (2) is unique and corresponds to the global minimum of $Q(\beta)$.

In order to facilitate estimation of patient weights, $\hat{\omega}_i$, it is necessary to center the baseline characteristics of the intervention data using the mean baseline characteristics from the comparator data.

## Optimization procedure

Following the centering of the baseline characteristics of the intervention study, patient weights can be estimated using the <tt>estimate_weights</tt> function in the <tt>maicplus</tt> package. This performs an optimization procedure to minimize $Q(\beta) = \sum_{i=1}^n \exp{(x_{i,ipd}.\beta)}$ and outputs a list containing:

* A character vector containing the names of the matching variables
* An analysis data frame of the intervention data with weights 

## Calculate weights

```{r}
weights <- estimate_weights(intervention_data = intervention_data,
                            match_cov = match_cov)
intervention_data <- intervention_data %>%
  mutate(wt = weights$wt, ARM = "Intervention")
```

## Weight diagnostics

Following the calculation of weights, it is necessary to determine whether the optimization procedure has worked correctly and whether the weights derived are sensible.

### Are the weights sensible?

#### Effective sample size
For a weighted estimate, the effective sample size (ESS) is the number of independent non-weighted individuals that would be required to give an estimate with the same precision as the weighted sample estimate. The approximate effective sample size is calculated as: $$ ESS =  \frac{({ \sum_{i=1}^n\hat{\omega}_i })^2}{ \sum_{i=1}^n \hat{\omega}_i^2} $$ A small ESS, relative to the original sample size, is an indication that the weights are highly variable and that the estimate may be unstable. This often occurs if there is very limited overlap in the distribution of the matching variables between the populations being compared. If there is insufficient overlap between populations it may not be possible to obtain reliable estimates of the weights

```{r}
weights$ess
```

In this example, the ESS is approximately 25% of the total number of patients in the intervention arm (500 patients in total). As this is a considerable reduction from the total number of patients, estimates using this weighted data may be unreliable. The reliability of the estimate could be explored by considering matching on a subset of the matching variables, for example, those considered most important. However, unless all prognostic factors and effect modifiers are included in the adjustment, the estimates will remain biased.[@phillippo2016a;@phillippo2019population]

#### Rescaled weights

It is easier to examine the distribution of the weights by scaling them, so that the rescaled weights are relative to the original unit weights of each individual. In other words, a rescaled weight $>$ 1 means that an individual carries more weight in the re-weighted population than the original data and a rescaled weight $<$ 1 means that an individual carries less weight in the
re-weighted population than the original data. The rescaled weights are calculated as:

$$\tilde{\omega}_i  =  \frac{  \hat{\omega}_i}{ \sum_{i=1}^n \hat{\omega}_i }\times N $$

A histogram of the rescaled weights (along with a histogram of the weights) can be produced using the <tt>hist_wts</tt> function in the <tt>maicplus</tt> package. <tt>bin_width</tt> needs to be adapted depending on the sample size in the data set by using the <tt>bin</tt> statement.

```{r}
# Plot histograms of unscaled and rescaled weights
# TODO
```

The distribution of rescaled weights can be further explored by producing a summary of the mean, standard deviation, median, minimum and maximum rescaled weight. The <tt>maicplus</tt> package includes the <tt>summarize_wts</tt> function to produce this summary for the rescaled weights and the weights.

```{r}
weight_summ <- summarize_wts(weights)
weight_summ
```

To understand which individuals are carrying more or less weight in the re-weighted population than the original data the <tt>profile_wts</tt> function in the <tt>MAIC</tt> package creates a data set with a unique set of weights and the corresponding patient profile based on the matching variables. When matching on a continuous variable there will be multiple unique weights and the output from this function is less useful. When there is a small set of unique weights <tt>profile_wts</tt> is useful to describe those patients who have more or less influence on the weighted analyses. 

```{r}
profile_data <- intervention_data %>%
  mutate(wt = weights$wt, wt_rs = weights$wt_rs)
profile_data <- profile_data[!duplicated(profile_data[,match_cov]), c(match_cov, "wt", "wt_rs")]
head(profile_data)
```

### Has the optimization worked?

The following function checks whether the re-weighted baseline characteristics for the intervention-treated patients match those aggregate characteristics from the comparator trial and outputs a summary that can be used for reporting.

```{r}
check_weights(intervention_data, target_pop, weights, match_cov)
```

# Incorporation of the weights in statistical analysis

## Comparator pseudo data {#comp}

Individual patient data was not available for the comparator study, therefore, pseudo individual patient data is required for these analyses to derive the relative treatment effects. These patients are given a weight of 1 for use in the weighted analysis.

Pseudo overall survival data was obtained for the comparator treatment by digitizing a reported overall survival Kaplan-Meier graph using the methodology of Guyot et al. [@guyot2012] Recently, Liu et al. introduced an R package <tt>IPDfromKM</tt> that facilitates this method. [@Liu2021]

It is common for binary endpoints to be reported as a percentage of patients with the event and therefore the example code below simulates pseudo-data for objective response based on the total number of patients and the proportion of responders.

The comparator data will include pseudo individual patient data from two different endpoints and it should be highlighted that there is no 1:1 relationship between endpoints for a given patient since these are reconstructed data and not actual observed data.

Naming of variables in the comparator data should be consistent with those used in the intervention IPD.

## Comparator pseudo data

```{r}
# Read in digitised pseudo survival data, column names must match intervention_input
# pseudo spelled wrong..
setwd("~/GitHub/maicplus/inst/dev/combined")
comparator_surv <- read.csv("pseudo_IPD.csv")
comparator_input <- comparator_surv %>%
                    mutate(wt = 1, ARM = "Comparator")

combined_data <-  bind_rows(intervention_data, comparator_input)
combined_data$ARM <- relevel(as.factor(combined_data$ARM), ref="Comparator")
combined_data$usubjid <- seq(dim(combined_data)[1])
```

## Estimating the relative effect 

Using the weights (not the rescaled weights) derived above, relative effects can
be estimated using:

* <tt>coxph</tt> for time to event endpoints via the use of the <tt>weights</tt>
statement to estimate a weighted HR from a Cox proportional hazards model
* <tt>glm</tt> for binary endpoints via the use of the <tt>weight</tt> statement
to estimate a weighted OR from logistic regression 

It is important to report the weighted relative effect with the unweighted relative effect to understand how the weighting has affected the analysis.

### Bootstrapping a confidence interval

The use of weights induces a within-subject correlation in outcomes, as observations can have weights that are unequal to one another. [@austin2016variance; @therneau2015adjusted] As such, it is necessary to use a variance estimator to take into account the lack of independence of observations. The two common approaches to this are robust variance estimation and bootstrapping. A simulation study was conducted by Austin et al to examine the different methods in the context of an inverse probability of treatment weighting (IPTW) survival analysis. [@austin2016variance] The author concluded that the use of a bootstrap estimator resulted in approximately correct estimates of standard errors and confidence intervals with the correct coverage rate. The other estimators resulted in biased estimates of standard errors and confidence intervals with incorrect coverage rates. The use of a bootstrap type estimator is also intuitively appealing, a robust estimator assumes that the weights are known and not subject to any sampling uncertainty. However, a bootstrap estimator allows for quantification of the uncertainty in the estimation of the weights. 

Bootstrapping involves:

1. Sampling, with replacement, from the patients in the intervention arm (a bootstrap sample)
2. Estimating a set of weights for each of these bootstrapped data sets and 
3. Estimating a hazard ratio (HR)/odds ratio (OR) using each set of estimated weights. 

This procedure is repeated multiple times to obtain a distribution of HRs/ORs. For this example, bootstrap estimates of the HRs/ORs were calculated using the <tt>boot</tt> package. An argument for the <tt>boot</tt> function is <tt>statistic</tt> which is a function which when applied to data returns a vector containing the statistic(s) of interest. The <tt>bootstrap_HR</tt> and <tt>bootstrap_OR</tt> in the <tt>MAIC</tt> package can be used for this purpose.

Two different methods for estimating a 95% confidence
interval (CI) from the bootstrap samples were explored:[@efron1994; @diciccio1996; @efron1987]

* Percentile CIs 
    * This method takes the 2.5th and 97.5th percentiles and can be implemented
    using the <tt>type="perc"</tt> statement in the <tt>boot.ci</tt> function
* Bias-corrected and accelerated (BCa) CIs 
    * This method attempts to correct for any bias and skewness in the
    distribution of bootstrap estimates and can be implemented using
    <tt>type="bca"</tt> statement in the <tt>boot.ci</tt> function)
    * The BCa method also takes percentiles but they are not necessarily the
    2.5th and 97.5th percentiles (the choice of percentiles depends on an
    acceleration parameter [estimated through jackknife re-sampling] and a bias
    correction factor [proportion of bootstrap estimates less than the original
    estimator])

### Add Description for Robust Sandwich estimators


## Example for survival data
### Kaplan-Meier plot

To visualize the effect of the weighting compared to the unadjusted data, it is useful to plot a Kaplan-Meier. The figure below shows there is a clear treatment benefit of the intervention compared to the comparator. The treatment effect increases once the data is weighted. This treatment effect is quantified in the next section.

To note, the number of patients at the start of the Kaplan-Meier plot in the weighted population is equivalent to the sum of the weights. This will be different to the ESS.

```{r}
##### Drawing kaplan meier plots
# Unweighted intervention data
KM_int <- survfit(formula = Surv(Time, Event==1) ~ 1,
                  data = intervention_data,
                  type="kaplan-meier")
# Weighted intervention data
KM_int_wtd <- survfit(formula = Surv(Time, Event==1) ~ 1,
                      data = intervention_data,
                      weights = weights$wt,
                      type="kaplan-meier")
# Comparator data
KM_comp <- survfit(formula = Surv(Time, Event==1) ~ 1,
                   data = comparator_input,
                   type="kaplan-meier")

# Combine the survfit objects ready for ggsurvplot
KM_list <- list(Intervention = KM_int,
                Intervention_weighted = KM_int_wtd,
                Comparator = KM_comp)

#Produce the Kaplan-Meier plot
KM_plot <- ggsurvplot(KM_list,
                      linetype = c(1,1,2),
                      combine = TRUE,
                      risk.table= TRUE, # numbers at risk displayed on the plot
                      break.x.by= 30, # need to change depending on plotting days/month
                      xlab="Time (days)",
                      ylab="Overall survival", # need?
                      censor=TRUE,
                      legend.title = "Treatment",
                      legend=c(0.85,0.82),
                      title = "Kaplan-Meier plot of overall survival",
                      legend.labs=c("Intervention", "Intervention weighted", "Comparator"),
                      risk.table.y.text.col = T,
                      risk.table.y.text = FALSE,
                      tables.theme = theme_cleantable(),
                      ggtheme = theme_classic(base_size = 13),
                      conf.int = FALSE)
KM_plot
```


### Estimating the hazard ratio (HR)

In this example, the weighted HR 0.30 (95% CI: 0.21, 0.42) shows a larger treatment effect (HR further from 1) than the unweighted HR 0.37 (95% CI: 0.30, 0.46). The median of the bootstrap HR samples is the same as the HR from the weighted Cox model to two decimal places (HR is 0.29). In this example, the percentile CI (0.21, 0.39) and BCa confidence interval (0.23, 0.41) are identical to two decimal places suggesting the bootstrap samples are relatively normally distributed. Finally, it should be noted that results are relatively consistent across all methods, the intervention treatment significantly reduces the hazard of death compared with the comparator treatment.

## Cox model

```{r}
# Fit a Cox model without weights to estimate the unweighted HR
unweighted_cox <- coxph(Surv(Time, Event==1) ~ ARM, data = combined_data)

HR_CI_cox <- summary(unweighted_cox)$conf.int %>%
  as.data.frame() %>%
  transmute("HR" = `exp(coef)`, "HR_low_CI" = `lower .95`, "HR_upp_CI" = `upper .95`)
HR_CI_cox

# Fit a Cox model with weights to estimate the weighted HR
weighted_cox <- coxph(Surv(Time, Event==1) ~ ARM, data = combined_data, weights = wt)

HR_CI_cox_wtd <- summary(weighted_cox)$conf.int %>%
  as.data.frame() %>%
  transmute("HR" = `exp(coef)`, "HR_low_CI" = `lower .95`, "HR_upp_CI" = `upper .95`)
HR_CI_cox_wtd
```


```{r, results = 'hide'}
set.seed(1)
# Bootstrap 1000 HRs
HR_bootstraps <- boot(data = intervention_data, # intervention data
                      statistic = bootstrap_HR, # bootstrap the HR (defined in the MAIC package)
                      match_cov = match_cov, # matching variables
                      R = 1000, # number of bootstrap samples
                      comparator_input = comparator_input, # comparator pseudo data
                      model = Surv(Time, Event==1) ~ ARM # model to fit
                      )

# Median of the bootstrap samples
HR_median <- median(HR_bootstraps$t)

# Bootstrap CI - Percentile CI
boot_ci_HR <- boot.ci(boot.out = HR_bootstraps, index=1, type="perc")

# Bootstrap CI - BCa CI
boot_ci_HR_BCA <- boot.ci(boot.out = HR_bootstraps, index=1, type="bca")
```

```{r}
HR_median
boot_ci_HR
boot_ci_HR_BCA
```

### Bootstrapping diagnostics

To test the distribution of the bootstrapped HRs, a histogram can be plotted. If
the plot does not appear normally distributed, this may suggest that the BCa
approach is more appropriate than the percentile approach.

```{r}
# Summarize bootstrap estimates in a histogram
# Vertical lines indicate the median and upper and lower CIs
hist(HR_bootstraps$t, main = "", xlab = "Bootstrapped HR")
abline(v= quantile(HR_bootstraps$t, probs = c(0.025, 0.5, 0.975)), lty=2)
```

## Example for response data

### Estimating the odds ratio (OR)

In this example, the weighted OR 3.84 (95% CI: 2.56, 5.78) shows a smaller treatment effect (closer to 1) than the unweighted OR 5.32 (95% CI: 3.89, 7.28) indicating a smaller difference between treatments. The median of the bootstrap OR samples was similar to the OR from the weighted logistic regression model to two decimal places. The median OR from the bootstrap samples was 3.84. For this endpoint, the percentile CI (2.68 to 5.73) and BCa confidence interval (2.65,5.65) are similar, suggesting the bootstrap samples are relatively normally distributed. Finally, it should be noted that results are relatively consistent across all methods, the intervention treatment significantly increases the odds of response compared with the comparator treatment.

When deriving the weighted OR using the GLM, the warnings have been suppressed, since the function expects integer values for response (i.e. 1 or 0) however, when the weights function is used, the response values are no longer a integer value.

```{r}
# Simulate response data based on the known proportion of responders
comparator_n <- nrow(comparator_surv) # total number of patients in the comparator data
comparator_prop_events <- 0.4 # proportion of responders
# Calculate number with event
# Use round() to ensure we end up with a whole number of people
# number without an event = Total N - number with event to ensure we keep the same number of patients
n_with_event <- round(comparator_n*comparator_prop_events, digits = 0)
comparator_binary <- data.frame("response"= c(rep(1, n_with_event), rep(0, comparator_n - n_with_event)))

# Join response comparator data
# (note the rows do not represent observations from a particular patient)
comparator_input <- comparator_binary %>%
  mutate(wt=1, ARM="Comparator") # All patients have weight = 1

combined_data <-  bind_rows(intervention_data, comparator_input)
combined_data$ARM <- relevel(as.factor(combined_data$ARM), ref="Comparator")
combined_data$usubjid <- seq(dim(combined_data)[1])
```


```{r}
unweighted_OR <- glm(formula = response ~ ARM,
                     family = binomial(link="logit"),
                     data = combined_data)

# Log odds ratio
log_OR_CI <- cbind(coef(unweighted_OR), confint.default(unweighted_OR, level = 0.95))[2,]

# Odds ratio
OR_CI <- exp(log_OR_CI)
names(OR_CI) <- c("OR", "OR_low_CI", "OR_upp_CI")
OR_CI

# Fit a logistic regression model with weights to estimate the weighted OR
weighted_OR <- suppressWarnings(glm(formula = response~ ARM,
                                    family = binomial(link="logit"),
                                    data = combined_data,
                                    weight = wt))

# Weighted log odds ratio
log_OR_CI_wtd <- cbind(coef(weighted_OR), confint.default(weighted_OR, level = 0.95))[2,]

# Weighted odds ratio
OR_CI_wtd <- exp(log_OR_CI_wtd)
names(OR_CI_wtd) <- c("OR", "OR_low_CI", "OR_upp_CI")
OR_CI_wtd

# Robust standard error
vmod <- clubSandwich::vcovCR(weighted_OR, cluster=combined_data$usubjid,type="CR2")
coef_res <- clubSandwich::conf_int(weighted_OR,vmod,coef=2)

OR_CI_robust <- with(coef_res, c(beta, CI_L, CI_U, SE))
names(OR_CI_robust) <- c("Estimate", "Lower 95% CI", "Upper 95% CI", "SE")
OR_CI_robust
```

```{r, results = 'hide'}
# Bootstrap 1000 HRs
set.seed(1)
OR_bootstraps <- boot(data = intervention_data, # intervention data
                      statistic = bootstrap_OR, # bootstrap the HR (defined in the MAIC package)
                      R=1000, # number of bootstrap samples
                      match_cov = match_cov, # matching variables
                      comparator_input = comparator_input, # comparator pseudo data
                      model = 'response ~ ARM' # model to fit
                      )

# Median of the bootstrap samples
OR_median <- median(OR_bootstraps$t)

# Bootstrap CI - Percentile CI
boot_ci_OR <- boot.ci(boot.out = OR_bootstraps, index=1, type="perc")

# Bootstrap CI - BCa CI
boot_ci_OR_BCA <- boot.ci(boot.out = OR_bootstraps, index=1, type="bca")
```

```{r}
OR_median
boot_ci_OR
boot_ci_OR_BCA

# Summarize bootstrap estimates in a histogram
# Vertical lines indicate the median and upper and lower CIs
hist(OR_bootstraps$t, main = "", xlab = "Boostrapped OR")
abline(v= quantile(OR_bootstraps$t, probs = c(0.025,0.5,0.975)), lty=2)
```


# Things to add

check for overlap in effect modifiers/ prognostic factors, sandwich estimator for HR/OR, check for high corrleation among covariates

# References
